% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rxgboost.R
\name{SL.cvboost}
\alias{SL.cvboost}
\title{Wrapper function for xgboost based on \code{rlearner::rboost}}
\usage{
SL.cvboost(
  Y,
  X,
  newX = X,
  family = gaussian(),
  obsWeights = NULL,
  id = NULL,
  k_folds = 5L,
  ntrees_max = 1000,
  num_search_rounds = 10,
  early_stopping_rounds = 10,
  nthread = 1,
  verbose = FALSE,
  print_every_n = 100,
  ...
)
}
\arguments{
\item{Y}{The outcome in the training data set. Must be a numeric vector.}

\item{X}{The predictor variables in the training data set, usually a data.frame.}

\item{newX}{The predictor variables in the validation data set. The structure should match X. Defaults to X.}

\item{family}{Currently allows gaussian or binomial to describe the error distribution. Link function information will be ignored and should be contained in the method argument below.}

\item{obsWeights}{Optional observation weights variable.}

\item{id}{Optional cluster identification variable. Not currently supported.}

\item{k_folds}{Number of folds used in cross validation (CV). Defaults to 5-fold CV.}

\item{ntrees_max}{The maximum number of trees to grow for xgboost.}

\item{num_search_rounds}{The number of random sampling of hyperparameter combinations for cross validating on xgboost trees.}

\item{early_stopping_rounds}{The number of rounds the test error stops decreasing by which the cross validation in finding the optimal number of trees stops.}

\item{nthread}{The number of threads to use.}

\item{verbose}{Boolean; whether to print statistic.}

\item{print_every_n}{The number of iterations (in each iteration, a tree is grown) by which the code prints out information.}

\item{...}{Additional SuperLearner arguments. Not currently supported.}
}
\value{
A list containing a numeric vector \code{pred} of predictions at \code{newX} and a list \code{fit} containing an \code{r.xgboost} object based on output of the \code{rlearner::cvboost} function. Run the command \code{?rlearner::cvboost} for additional details about individual elements of \code{fit}.
}
\description{
This function automates hyperparameter tuning for prediction using \code{xgboost}. Its input/output follows the template required for wrapper functions in the \code{SuperLearner} package.
}
\examples{
set.seed(1)
n = 100; p = 5

x = matrix(rnorm(n*p), n, p)
y = pmax(x[,1], 0) + x[,2] + pmin(x[,3], 0) + rnorm(n)
fit = SL.cvboost(y, data.frame(x), newX = data.frame(x),
family = gaussian(), obsWeights = NULL)
est = fit$pred
}
